import os
import cloudscraper
import requests
from bs4 import BeautifulSoup
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes
from flask import Flask
import threading
import logging
from data_logger import log_interaction, save_to_excel

# 专转  
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 专转
TOKEN = os.getenv("TELEGRAM_TOKEN")
if not TOKEN:
    logger.error("砖: 拽  专!")
    exit(1)

NEWS_SITES = {
    'ynet': 'https://www.ynet.co.il/news',
    'arutz7': 'https://www.inn.co.il/api/NewAPI/Cat?type=10',
    'walla': 'https://news.walla.co.il/',
    'sport5': 'https://m.sport5.co.il/',
    'sport1': 'https://sport1.maariv.co.il/',
    'one': 'https://m.one.co.il/mobile/'
}

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124'
}

# 爪专转 驻拽爪转 Flask 
app = Flask(__name__)

# 爪专转 驻拽爪转 Telegram
bot_app = Application.builder().token(TOKEN).build()

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    username = update.message.from_user.username
    logger.info(f"User {user_id} sent /start, username: {username}")  #  驻砖
    log_interaction(user_id, "/start", username)
    await update.message.reply_text("专 ! 砖转砖 -/latest 拽.")

async def download(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    username = update.message.from_user.username
    logger.info(f"User {user_id} sent /download, username: {username}")  #  驻砖
    log_interaction(user_id, "/download", username)
    SECRET_PASSWORD = os.getenv("DOWNLOAD_PASSWORD")

    if not SECRET_PASSWORD:
        await update.message.reply_text("砖: 住住  专转 砖专转!")
        return
    
    if not context.args or context.args[0] != SECRET_PASSWORD:
        await update.message.reply_text("住住 砖!  砖.")
        return
    
    try:
        filename = save_to_excel()
        if not os.path.exists(filename):
            await update.message.reply_text("砖: 拽抓  爪专!")
            return
        with open(filename, 'rb') as file:
            await update.message.reply_document(document=file, filename="bot_usage.xlsx")
        await update.message.reply_text(" 转 砖!")
        os.remove(filename)
    except Exception as e:
        logger.error(f"砖 砖转 拽抓: {e}")
        await update.message.reply_text(f"砖 专: {str(e)}")

def scrape_ynet():
    try:
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(NEWS_SITES['ynet'], headers=HEADERS).text, 'html.parser')
        return [{'title': item.text.strip(), 'link': item.find('a')['href']} for item in soup.select('div.slotTitle')[:5]]
    except Exception as e:
        logger.error(f"砖 -Ynet: {e}")
        return []

def scrape_arutz7():
    try:
        response = requests.get(NEWS_SITES['arutz7'], headers=HEADERS)
        response.raise_for_status()
        data = response.json()
        items = data.get('Items', []) if 'Items' in data else data
        return [
            {
                'time': item.get('time', item.get('itemDate', " 砖注")[:16].replace('T', ' ')),
                'title': item.get('title', ' 转专转'),
                'link': item.get('shotedLink', item.get('link', '#'))
            } for item in items[:3]
        ]
    except Exception as e:
        logger.error(f"砖 注专抓 7: {e}")
        return []

def scrape_walla():
    try:
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(NEWS_SITES['walla'], headers=HEADERS).text, 'html.parser')
        items = soup.select_one('div.top-section-newsflash.no-mobile').select('a') if soup.select_one('div.top-section-newsflash.no-mobile') else []
        results = []
        for item in items:
            title = item.get_text(strip=True)
            if title in ["拽 砖转", "拽"]:
                continue
            if len(title) > 5 and title[2] == ':':
                title = title[:5] + ": " + title[5:]
            link = item['href']
            if not link.startswith('http'):
                link = f"https://news.walla.co.il{link}"
            results.append({'title': title, 'link': link})
        return results[:3]
    except Exception as e:
        logger.error(f"砖 -Walla: {e}")
        return []

def scrape_sport5():
    try:
        url = 'https://m.sport5.co.il/'
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(url, headers=HEADERS).text, 'html.parser')
        
        articles = soup.select('nav.posts-list.posts-list-articles ul li')
        
        results = []
        for item in articles[:3]:
            link_tag = item.find('a', class_='item')
            title_tag = item.find('h2', class_='post-title')
            time_tag = item.find('em', class_='time')
            
            title = title_tag.get_text(strip=True) if title_tag else ' 转专转'
            link = link_tag['href'] if link_tag else '#'
            time = time_tag.get_text(strip=True) if time_tag else ' 砖注'
            
            if link and not link.startswith('http'):
                link = f"https://m.sport5.co.il{link}"
            
            results.append({
                'time': time,
                'title': title,
                'link': link
            })
        
        logger.info(f"住拽专驻 住驻专 5 爪: {len(results)} 转转 砖驻")
        return results, None
    except Exception as e:
        logger.error(f"砖 住拽专驻 住驻专 5: {e}")
        return [], f"砖  注: {str(e)}"

def scrape_sport1():
    try:
        url = 'https://sport1.maariv.co.il/'
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(url, headers=HEADERS).text, 'html.parser')
        
        articles = soup.select('div.hot-news-container article.article-card')
        
        results = []
        for item in articles[:3]:
            link_tag = item.find_parent('a', class_='image-wrapper')
            title_tag = item.find('h3', class_='article-card-title')
            time_tag = item.find('time', class_='entry-date')
            
            title = title_tag.get_text(strip=True) if title_tag else ' 转专转'
            link = link_tag['href'] if link_tag else '#'
            time = time_tag.get_text(strip=True) if time_tag else ' 砖注'
            
            if link and not link.startswith('http'):
                link = f"https://sport1.maariv.co.il{link}"
            
            results.append({
                'time': time,
                'title': title,
                'link': link
            })
        
        logger.info(f"住拽专驻 住驻专 1 爪: {len(results)} 转转 砖驻")
        return results, None
    except Exception as e:
        logger.error(f"砖 住拽专驻 住驻专 1: {e}")
        return [], f"砖  注: {str(e)}"

def scrape_one():
    try:
        url = 'https://m.one.co.il/mobile/'
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(url, headers=HEADERS).text, 'html.parser')
        
        articles = soup.select('a.mobile-hp-article-plain')
        
        results = []
        for item in articles[:3]:
            link_tag = item
            title_tag = item.find('h1')
            time = ' 砖注'
            
            title = title_tag.get_text(strip=True) if title_tag else ' 转专转'
            link = link_tag['href'] if link_tag else '#'
            
            if link and not link.startswith('http'):
                link = f"https://m.one.co.il{link}"
            
            results.append({
                'time': time,
                'title': title,
                'link': link
            })
        
        logger.info(f"住拽专驻 ONE 爪: {len(results)} 转转 砖驻")
        return results, None
    except Exception as e:
        logger.error(f"砖 住拽专驻 ONE: {e}")
        return [], f"砖  注: {str(e)}"

async def latest(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    username = update.message.from_user.username
    logger.info(f"User {user_id} sent /latest, username: {username}")  #  驻砖
    log_interaction(user_id, "/latest", username)
    await update.message.reply_text("驻砖 拽...")
    ynet_news = scrape_ynet()
    arutz7_news = scrape_arutz7()
    walla_news = scrape_walla()

    news = {'Ynet': ynet_news, '注专抓 7': arutz7_news, 'Walla': walla_news}
    message = " **拽 专** \n\n"
    for site, articles in news.items():
        message += f"**{site}:**\n"
        if articles:
            for idx, article in enumerate(articles[:3], 1):
                if 'time' in article:
                    message += f"{idx}. [{article['time']} - {article['title']}]({article['link']})\n"
                else:
                    message += f"{idx}. [{article['title']}]({article['link']})\n"
        else:
            message += " 转 注 专注\n"
        message += "\n"
    
    keyboard = [[InlineKeyboardButton("金 拽转 拽 住驻专", callback_data='sports_news')]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(text=message, parse_mode='Markdown', disable_web_page_preview=True, reply_markup=reply_markup)

async def sports_news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    user_id = query.from_user.id
    username = query.from_user.username
    logger.info(f"User {user_id} triggered sports_news, username: {username}")  #  驻砖
    log_interaction(user_id, "sports_news", username)
    await query.answer()
    
    await query.message.reply_text("驻砖 拽 住驻专...")
    
    sport5_news, sport5_error = scrape_sport5()
    sport1_news, sport1_error = scrape_sport1()
    one_news, one_error = scrape_one()
    
    message = "**住驻专 5**\n"
    if sport5_news:
        for idx, article in enumerate(sport5_news[:3], 1):
            if 'time' in article:
                message += f"{idx}. {article['time']} - [{article['title']}]({article['link']})\n"
            else:
                message += f"{idx}. [{article['title']}]({article['link']})\n"
    else:
        message += " 转 爪 拽\n"
        if sport5_error:
            message += f"**驻专 砖:** {sport5_error}\n"
    
    message += "\n**住驻专 1**\n"
    if sport1_news:
        for idx, article in enumerate(sport1_news[:3], 1):
            if 'time' in article:
                message += f"{idx}. {article['time']} - [{article['title']}]({article['link']})\n"
            else:
                message += f"{idx}. [{article['title']}]({article['link']})\n"
    else:
        message += " 转 爪 拽\n"
        if sport1_error:
            message += f"**驻专 砖:** {sport1_error}\n"
    
    message += "\n**ONE**\n"
    if one_news:
        for idx, article in enumerate(one_news[:3], 1):
            message += f"{idx}. [{article['title']}]({article['link']})\n"
    else:
        message += " 转 爪 拽\n"
        if one_error:
            message += f"**驻专 砖:** {one_error}\n"
    
    keyboard = [[InlineKeyboardButton(" 专 注 专砖", callback_data='latest_news')]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.message.reply_text(text=message, parse_mode='Markdown', disable_web_page_preview=True, reply_markup=reply_markup)

async def latest_news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    user_id = query.from_user.id
    username = query.from_user.username
    logger.info(f"User {user_id} triggered latest_news, username: {username}")  #  驻砖
    log_interaction(user_id, "latest_news", username)
    await query.answer()
    
    ynet_news = scrape_ynet()
    arutz7_news = scrape_arutz7()
    walla_news = scrape_walla()

    news = {'Ynet': ynet_news, '注专抓 7': arutz7_news, 'Walla': walla_news}
    message = " **拽 专** \n\n"
    for site, articles in news.items():
        message += f"**{site}:**\n"
        if articles:
            for idx, article in enumerate(articles[:3], 1):
                if 'time' in article:
                    message += f"{idx}. [{article['time']} - {article['title']}]({article['link']})\n"
                else:
                    message += f"{idx}. [{article['title']}]({article['link']})\n"
        else:
            message += " 转 注 专注\n"
        message += "\n"
    
    keyboard = [[InlineKeyboardButton("金 拽转 拽 住驻专", callback_data='sports_news')]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await query.message.reply_text(text=message, parse_mode='Markdown', disable_web_page_preview=True, reply_markup=reply_markup)

# 砖专转 Flask  砖拽砖 驻专
@app.route('/')
def home():
    return "Bot is alive!"

def run_flask():
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)

if __name__ == "__main__":
    logger.info("转 转  注 Polling 砖专转 ...")
    
    # 专转 驻
    bot_app.add_handler(CommandHandler("start", start))
    bot_app.add_handler(CommandHandler("latest", latest))
    bot_app.add_handler(CommandHandler("download", download))
    bot_app.add_handler(CallbackQueryHandler(sports_news, pattern='sports_news'))
    bot_app.add_handler(CallbackQueryHandler(latest_news, pattern='latest_news'))

    # 专爪转 Flask 砖专砖专 驻专
    flask_thread = threading.Thread(target=run_flask, daemon=True)
    flask_thread.start()

    # 转 专爪转 Polling
    bot_app.run_polling(allowed_updates=Update.ALL_TYPES)