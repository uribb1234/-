import os
import cloudscraper
import requests
from bs4 import BeautifulSoup
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes
from flask import Flask
import threading
import logging

# ×”×’×“×¨×ª ×œ×•×’×™× ×œ×“×™×‘××’
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ×”×’×“×¨×•×ª
TOKEN = os.getenv("TELEGRAM_TOKEN")
if not TOKEN:
    logger.error("×©×’×™××”: ×”×˜×•×§×Ÿ ×œ× ××•×’×“×¨!")
    exit(1)

NEWS_SITES = {
    'ynet': 'https://www.ynet.co.il/news',
    'arutz7': 'https://www.inn.co.il/api/NewAPI/Cat?type=10',
    'walla': 'https://news.walla.co.il/',
    'sport5': 'https://m.sport5.co.il/'
}

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124'
}

# ×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×™×ª Flask
app = Flask(__name__)

def run_flask():
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("×‘×¨×•×š ×”×‘×! ×”×©×ª××© ×‘-/latest ×œ××‘×–×§×™×.")

def scrape_ynet():
    try:
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(NEWS_SITES['ynet'], headers=HEADERS).text, 'html.parser')
        return [{'title': item.text.strip(), 'link': item.find('a')['href']} for item in soup.select('div.slotTitle')[:5]]
    except Exception as e:
        logger.error(f"×©×’×™××” ×‘-Ynet: {e}")
        return []

def scrape_arutz7():
    try:
        response = requests.get(NEWS_SITES['arutz7'], headers=HEADERS)
        response.raise_for_status()
        data = response.json()
        items = data.get('Items', []) if 'Items' in data else data
        return [
            {
                'time': item.get('time', item.get('itemDate', "×œ×œ× ×©×¢×”")[:16].replace('T', ' ')),
                'title': item.get('title', '×œ×œ× ×›×•×ª×¨×ª'),
                'link': item.get('shotedLink', item.get('link', '#'))
            } for item in items[:3]
        ]
    except Exception as e:
        logger.error(f"×©×’×™××” ×‘×¢×¨×•×¥ 7: {e}")
        return []

def scrape_walla():
    try:
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(NEWS_SITES['walla'], headers=HEADERS).text, 'html.parser')
        items = soup.select_one('div.top-section-newsflash.no-mobile').select('a') if soup.select_one('div.top-section-newsflash.no-mobile') else []
        results = []
        for item in items:
            title = item.get_text(strip=True)
            if title in ["××‘×–×§×™ ×—×“×©×•×ª", "××‘×–×§×™×"]:
                continue
            if len(title) > 5 and title[2] == ':':
                title = title[:5] + ": " + title[5:]
            link = item['href']
            if not link.startswith('http'):
                link = f"https://news.walla.co.il{link}"
            results.append({'title': title, 'link': link})
        return results[:3]
    except Exception as e:
        logger.error(f"×©×’×™××” ×‘-Walla: {e}")
        return []

def scrape_sport5():
    try:
        url = 'https://m.sport5.co.il/'
        scraper = cloudscraper.create_scraper()
        soup = BeautifulSoup(scraper.get(url, headers=HEADERS).text, 'html.parser')
        
        articles = soup.select('nav.posts-list.posts-list-articles ul li')
        
        results = []
        for item in articles[:3]:
            link_tag = item.find('a', class_='item')
            title_tag = item.find('h2', class_='post-title')
            time_tag = item.find('em', class_='time')
            
            title = title_tag.get_text(strip=True) if title_tag else '×œ×œ× ×›×•×ª×¨×ª'
            link = link_tag['href'] if link_tag else '#'
            time = time_tag.get_text(strip=True) if time_tag else '×œ×œ× ×©×¢×”'
            
            if link and not link.startswith('http'):
                link = f"https://m.sport5.co.il{link}"
            
            results.append({
                'time': time,
                'title': title,
                'link': link
            })
        
        logger.info(f"×¡×§×¨×™×¤×™× ×’ ×¡×¤×•×¨×˜ 5 ×”×¦×œ×™×—: {len(results)} ×›×ª×‘×•×ª × ×©×œ×¤×•")
        return results, None
    
    except Exception as e:
        logger.error(f"×©×’×™××” ×‘×¡×§×¨×™×¤×™× ×’ ×¡×¤×•×¨×˜ 5: {e}")
        return [], f"×©×’×™××” ×œ× ×™×“×•×¢×”: {str(e)}"

async def latest(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("××—×¤×© ××‘×–×§×™×...")
    ynet_news = scrape_ynet()
    arutz7_news = scrape_arutz7()
    walla_news = scrape_walla()

    news = {'Ynet': ynet_news, '×¢×¨×•×¥ 7': arutz7_news, 'Walla': walla_news}
    message = "ğŸ“° **×”××‘×–×§×™× ×”××—×¨×•× ×™×** ğŸ“°\n\n"
    for site, articles in news.items():
        message += f"**{site}:**\n"
        if articles:
            for idx, article in enumerate(articles[:3], 1):
                if 'time' in article:
                    message += f"{idx}. [{article['time']} - {article['title']}]({article['link']})\n"
                else:
                    message += f"{idx}. [{article['title']}]({article['link']})\n"
        else:
            message += "×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ×›×¨×’×¢\n"
        message += "\n"
    
    keyboard = [[InlineKeyboardButton("âš½ğŸ€ ×§×‘×œ×ª ××‘×–×§×™ ×¡×¤×•×¨×˜", callback_data='sports_news')]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(text=message, parse_mode='Markdown', disable_web_page_preview=True, reply_markup=reply_markup)

async def sports_news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    await query.message.reply_text("××—×¤×© ××‘×–×§×™ ×¡×¤×•×¨×˜... (×”×¤×•× ×§×¦×™×” ×¢×“×™×™×Ÿ ×‘×¤×™×ª×•×—, ×™×ª×›× ×• ×ª×§×œ×•×ª)")
    
    sport5_news, error_message = scrape_sport5()
    
    message = "ğŸ€âš½ **××‘×–×§×™ ×¡×¤×•×¨×˜ ××—×¨×•× ×™× - ×¡×¤×•×¨×˜ 5** ğŸ€âš½\n\n"
    if sport5_news:
        for idx, article in enumerate(sport5_news[:3], 1):
            if 'time' in article:
                message += f"{idx}. [{article['time']} - {article['title']}]({article['link']})\n"
            else:
                message += f"{idx}. [{article['title']}]({article['link']})\n"
    else:
        message += "×œ× × ×™×ª×Ÿ ×œ××¦×•× ××‘×–×§×™×\n"
        if error_message:
            message += f"**×¤×¨×˜×™ ×”×©×’×™××”:** {error_message}"
    
    await query.message.reply_text(text=message, parse_mode='Markdown', disable_web_page_preview=True)

@app.route('/')
def home():
    return "Bot is alive!"

if __name__ == "__main__":
    logger.info("××ª×—×™×œ ××ª ×”×©×¨×ª ×•×”×‘×•×˜...")
    
    flask_thread = threading.Thread(target=run_flask)
    flask_thread.start()
    
    logger.info(f"×× ×¡×” ×œ×”×ª×—×‘×¨ ×œ×˜×œ×’×¨× ×¢× ×”×˜×•×§×Ÿ: {TOKEN[:10]}...")
    try:
        bot_app = Application.builder().token(TOKEN).build()
        bot_app.add_handler(CommandHandler("start", start))
        bot_app.add_handler(CommandHandler("latest", latest))
        bot_app.add_handler(CallbackQueryHandler(sports_news, pattern='sports_news'))
        logger.info("×”×ª×—×‘×¨×ª×™ ×œ×˜×œ×’×¨× ×‘×”×¦×œ×—×”!")
        bot_app.run_polling(allowed_updates=Update.ALL_TYPES)
    except Exception as e:
        logger.error(f"×©×’×™××” ×‘×”×¨×¦×ª ×”×‘×•×˜: {e}")